{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.utils import multi_gpu_model\n",
    "from tensorflow.keras.layers import Dense, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
    "\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.activations import relu, sigmoid, softmax\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input with shape of height=32 and width=128 \n",
    "# inputs = Input(shape=(32, 128, 1))\n",
    "\n",
    "# conv_1 = Conv2D(16, (3,3), activation = 'relu', padding='same')(inputs)\n",
    "# pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
    " \n",
    "# conv_2 = Conv2D(32, (3,3), activation = 'relu', padding='same')(pool_1)\n",
    "# pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
    "\n",
    "# conv_3 = Conv2D(64, (3,3), activation = 'relu', padding='same')(pool_2)\n",
    "# conv_4 = Conv2D(64, (3,3), activation = 'relu', padding='same')(conv_3)\n",
    "# pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
    " \n",
    "# conv_5 = Conv2D(64, (3,3), activation = 'relu', padding='same')(pool_4)\n",
    "# # Batch normalization layer\n",
    "# batch_norm_5 = BatchNormalization()(conv_5)\n",
    " \n",
    "# conv_6 = Conv2D(64, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
    "# batch_norm_6 = BatchNormalization()(conv_6)\n",
    "# pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
    " \n",
    "# conv_7 = Conv2D(64, (2,2), activation = 'relu')(pool_6)\n",
    " \n",
    "# squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
    " \n",
    "# # bidirectional LSTM layers with units=128\n",
    "# blstm_1 = Bidirectional(CuDNNLSTM(128, return_sequences=True))(squeezed)\n",
    "# blstm_2 = Bidirectional(CuDNNLSTM(128, return_sequences=True))(blstm_1)\n",
    "\n",
    "# outputs = Dense(len(char_list) + 1, activation = 'softmax')(blstm_2)\n",
    "\n",
    "# # model to be used at test time\n",
    "# model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label_len = 23\n",
    "\n",
    "labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args \n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    " \n",
    "loss_out = Lambda(ctc_lambda_func, \n",
    "                  output_shape=(1,), \n",
    "                  name='ctc')([outputs, labels, input_length, label_length])\n",
    "\n",
    "#model to be used at training time\n",
    "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "file_path = \"C_LSTM_best.hdf5\"\n",
    "\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"model.h5\")\n",
    "# tf.saved_model.save(act_model, \"C_LSTM_best.hdf5\")\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "\n",
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.allow_custom_ops = True\n",
    "converter.experimental_new_converter = True\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "                                       tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
